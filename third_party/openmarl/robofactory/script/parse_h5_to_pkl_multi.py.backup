from typing import Union
import h5py
import numpy as np
from torch.utils.data import Dataset
from tqdm import tqdm
import os
import pdb
import pickle
import argparse
import multiprocessing as mp
from functools import partial
import gc

from mani_skill.utils.io_utils import load_json
from mani_skill.utils import sapien_utils
from mani_skill.utils import common

# loads h5 data into memory for faster access
def load_h5_data(data):
    out = dict()
    for k in data.keys():
        if isinstance(data[k], h5py.Dataset):
            out[k] = data[k][:]
        else:
            out[k] = load_h5_data(data[k])
    return out

class ManiSkillTrajectoryDataset(Dataset):
    """
    A general torch Dataset you can drop in and use immediately with just about any trajectory .h5 data generated from ManiSkill.
    This class simply is a simple starter code to load trajectory data easily, but does not do any data transformation or anything
    advanced. We recommend you to copy this code directly and modify it for more advanced use cases

    Args:
        dataset_file (str): path to the .h5 file containing the data you want to load
        load_count (int): the number of trajectories from the dataset to load into memory. If -1, will load all into memory
        success_only (bool): whether to skip trajectories that are not successful in the end. Default is false
        device: The location to save data to. If None will store as numpy (the default), otherwise will move data to that device
    """

    def __init__(self, dataset_file: str, load_count=-1, success_only: bool = False, device = None, batch_size=None) -> None:
        self.dataset_file = dataset_file
        self.device = device
        self.batch_size = batch_size  # If None, load all at once (original behavior)
        self.data = h5py.File(dataset_file, "r")
        json_path = dataset_file.replace(".h5", ".json")
        self.json_data = load_json(json_path)
        self.episodes = self.json_data["episodes"]
        self.env_info = self.json_data["env_info"]
        self.env_id = self.env_info["env_id"]
        self.env_kwargs = self.env_info["env_kwargs"]

        self.obs = []
        self.actions = []
        self.terminated = []
        self.truncated = []
        self.success, self.fail, self.rewards = None, None, None
        if load_count == -1:
            load_count = len(self.episodes)

        self.total_episodes = load_count
        
        # If batch_size is specified, only load episode metadata, not data
        if batch_size is not None:
            return
        
        # Original behavior: load all episodes into memory
        for eps_id in tqdm(range(load_count)):
            eps = self.episodes[eps_id]
            if success_only: 
                assert "success" in eps, "episodes in this dataset do not have the success attribute, cannot load dataset with success_only=True"
                if not eps["success"]:
                    continue

            # pdb.set_trace()
            trajectory = self.data[f"traj_{eps['episode_id']}"]
            trajectory = load_h5_data(trajectory)

            # Handle both dict (multi-agent) and array (single-agent) action structures
            if isinstance(trajectory["actions"], dict):
                # Multi-agent case: actions is a dict with agent keys
                first_agent_key = list(trajectory["actions"].keys())[0]
                eps_len = len(trajectory["actions"][first_agent_key])
            else:
                # Single-agent case: actions is directly an array
                eps_len = len(trajectory["actions"])

            # exclude the final observation as most learning workflows do not use it
            obs = common.index_dict_array(trajectory["obs"], slice(eps_len))
            self.obs = common.append_dict_array(self.obs, [obs])

            self.actions.append(trajectory["actions"])
            self.terminated.append(trajectory["terminated"])
            self.truncated.append(trajectory["truncated"])

            # handle data that might optionally be in the trajectory
            if "rewards" in trajectory:
                if self.rewards is None:
                    self.rewards = [trajectory["rewards"]]
                else:
                    self.rewards.append(trajectory["rewards"])
            if "success" in trajectory:
                if self.success is None:
                    self.success = [trajectory["success"]]
                else:
                    self.success.append(trajectory["success"])
            if "fail" in trajectory:
                if self.fail is None:
                    self.fail = [trajectory["fail"]]
                else:
                    self.fail.append(trajectory["fail"])

        # Specially, we maintain the gap between different episodes, which is useful for some learning algorithms
        # self.actions = np.vstack(self.actions)
        # self.terminated = np.concatenate(self.terminated)
        # self.truncated = np.concatenate(self.truncated)
        
        # if self.rewards is not None:
        #     self.rewards = np.concatenate(self.rewards)
        # if self.success is not None:
        #     self.success = np.concatenate(self.success)
        # if self.fail is not None:
        #     self.fail = np.concatenate(self.fail)

        def remove_np_uint16(x: Union[np.ndarray, dict]):
            if isinstance(x, dict):
                for k in x.keys():
                    x[k] = remove_np_uint16(x[k])
                return x
            else:
                if x.dtype == np.uint16:
                    return x.astype(np.int32)
                return x
        
        # uint16 dtype is used to conserve disk space and memory
        # you can optimize this dataset code to keep it as uint16 and process that
        # dtype of data yourself. for simplicity we simply cast to a int32 so
        # it can automatically be converted to torch tensors without complaint
        # self.obs = remove_np_uint16(self.obs)

        if device is not None:
            self.actions = sapien_utils.to_tensor(self.actions, device=device)
            self.obs = sapien_utils.to_tensor(self.obs, device=device)
            self.terminated = sapien_utils.to_tensor(self.terminated, device=device)
            self.truncated = sapien_utils.to_tensor(self.truncated, device=device)
            if self.rewards is not None:
                self.rewards = sapien_utils.to_tensor(self.rewards, device=device)
            if self.success is not None:
                self.success = sapien_utils.to_tensor(self.terminated, device=device)
            if self.fail is not None:
                self.fail = sapien_utils.to_tensor(self.truncated, device=device)

    def __len__(self):
        if self.batch_size is not None:
            return self.total_episodes
        return len(self.actions)

    def load_single_episode(self, idx):
        """Load a single episode from h5 file without caching."""
        eps = self.episodes[idx]
        trajectory = self.data[f"traj_{eps['episode_id']}"]
        trajectory = load_h5_data(trajectory)
        
        # Handle both dict (multi-agent) and array (single-agent) action structures
        if isinstance(trajectory["actions"], dict):
            first_agent_key = list(trajectory["actions"].keys())[0]
            eps_len = len(trajectory["actions"][first_agent_key])
        else:
            eps_len = len(trajectory["actions"])
        
        obs = common.index_dict_array(trajectory["obs"], slice(eps_len))
        action = trajectory["actions"]
        terminated = trajectory["terminated"]
        truncated = trajectory["truncated"]
        
        res = dict(
            obs=obs,
            action=action,
            terminated=terminated,
            truncated=truncated,
        )
        
        if "rewards" in trajectory:
            res.update(reward=trajectory["rewards"])
        if "success" in trajectory:
            res.update(success=trajectory["success"][-1])
        if "fail" in trajectory:
            res.update(fail=trajectory["fail"][-1])
        
        if isinstance(action, dict):
            for k in action.keys():
                res.update({f"len_of_action_{k}": len(action[k])})
        else:
            res.update(len_of_action=len(action))
        res.update(len_of_success=1)
        
        return res

    def __getitem__(self, idx):
        # If using batch processing, load episode on-demand
        if self.batch_size is not None:
            return self.load_single_episode(idx)
        
        # Original behavior: access pre-loaded data
        action = self.actions[idx]
        obs = self.obs[idx]
        # print("trajectory", obs["sensor_data"]["base_camera"]["rgb"].shape)
        # pdb.set_trace()
        res = dict(
            obs=obs,
            action=action,
            terminated=self.terminated[idx],
            truncated=self.truncated[idx],
        )
        if self.rewards is not None:
            res.update(reward=self.rewards[idx])
        if self.success is not None:
            res.update(success=self.success[idx][-1])
        if self.fail is not None:
            res.update(fail=self.fail[idx][-1])
        if isinstance(action, dict):
           for k in action.keys():
                res.update({f"len_of_action_{k}": len(action[k])})
        else:
            res.update(len_of_action=len(action))
        res.update(
            len_of_success=len(self.success),
        )
        return res

def process_episode(args):
    """Process a single episode and save to pkl files for all agents.
    This function is designed for parallel processing with multiprocessing.
    """
    episode_id, dataset_file, task_name, agent_num = args
    
    # Open h5 file in this process
    data = h5py.File(dataset_file, "r")
    json_path = dataset_file.replace(".h5", ".json")
    json_data = load_json(json_path)
    episodes = json_data["episodes"]
    
    eps = episodes[episode_id]
    trajectory = data[f"traj_{eps['episode_id']}"]
    trajectory = load_h5_data(trajectory)
    
    # Handle both dict (multi-agent) and array (single-agent) action structures
    if isinstance(trajectory["actions"], dict):
        first_agent_key = list(trajectory["actions"].keys())[0]
        eps_len = len(trajectory["actions"][first_agent_key])
    else:
        eps_len = len(trajectory["actions"])
    
    obs = common.index_dict_array(trajectory["obs"], slice(eps_len))
    action = trajectory["actions"]
    
    res = dict(
        obs=obs,
        action=action,
    )
    
    # Process each agent (including global)
    for agent_id in range(agent_num + 1):
        base_dir = f"data/pkl_data/{task_name}" + "_Agent" + str(agent_id)
        head_camera_name = "head_camera_agent" + str(agent_id)
        wrist_camera_name = "wrist_camera_agent" + str(agent_id)
        
        if agent_id == agent_num:
            base_dir = f"data/pkl_data/{task_name}" + "_global"
            head_camera_name = "head_camera_global"
            wrist_camera_name = None  # Global doesn't have wrist camera
        
        # Create episode directory
        episode_dir = f"{base_dir}/episode{episode_id}"
        os.makedirs(episode_dir, exist_ok=True)
        
        # Get action length - handle both dict and array structures
        if isinstance(res["action"], dict):
            action_len = len(res["action"]["panda-0"])
        else:
            action_len = len(res["action"])
        
        if head_camera_name not in res["obs"]["sensor_data"]:
            continue
            
        min_len = min(action_len, len(res["obs"]["sensor_data"][head_camera_name]["rgb"]))
        
        for j in range(min_len):
            obs_dict = {}
            # Head camera (side view, fixed position)
            obs_dict["head_camera"] = {}
            obs_dict["head_camera"]["rgb"] = res["obs"]["sensor_data"][head_camera_name]["rgb"][j]
            obs_dict["head_camera"]["intrinsic_cv"] = res["obs"]["sensor_param"][head_camera_name]["intrinsic_cv"][j]
            obs_dict["head_camera"]["extrinsic_cv"] = res["obs"]["sensor_param"][head_camera_name]["extrinsic_cv"][j]
            obs_dict["head_camera"]["cam2world_gl"] = res["obs"]["sensor_param"][head_camera_name]["cam2world_gl"][j]
            
            # Wrist camera (mounted on robot end-effector) - only for agents, not global
            if wrist_camera_name is not None and wrist_camera_name in res["obs"]["sensor_data"]:
                obs_dict["wrist_camera"] = {}
                obs_dict["wrist_camera"]["rgb"] = res["obs"]["sensor_data"][wrist_camera_name]["rgb"][j]
                obs_dict["wrist_camera"]["intrinsic_cv"] = res["obs"]["sensor_param"][wrist_camera_name]["intrinsic_cv"][j]
                obs_dict["wrist_camera"]["extrinsic_cv"] = res["obs"]["sensor_param"][wrist_camera_name]["extrinsic_cv"][j]
                obs_dict["wrist_camera"]["cam2world_gl"] = res["obs"]["sensor_param"][wrist_camera_name]["cam2world_gl"][j]
            
            if agent_id == agent_num:
                step_data = dict(
                    pointcloud=None,
                    joint_action=None,
                    endpose=None,
                    observation=obs_dict,
                )
            else:
                # Get action for this agent - handle both dict and array structures
                if isinstance(res["action"], dict):
                    agent_action = res["action"][f'panda-{agent_id}'][j]
                else:
                    # For single-agent, use the action directly
                    agent_action = res["action"][j]
                
                step_data = dict(
                    pointcloud=None,
                    joint_action=agent_action,
                    endpose=agent_action,
                    observation=obs_dict,
                )
            with open(f"{episode_dir}/{j}.pkl", "wb") as f:
                pickle.dump(step_data, f)
    
    data.close()
    gc.collect()  # Force garbage collection to free memory
    
    return episode_id

def main(load_num, task_name, agent_num, batch_size=5, num_workers=16):
    """
    Main function with batch processing and parallel processing support.
    
    Args:
        load_num: Number of episodes to process
        task_name: Name of the task
        agent_num: Number of agents
        batch_size: Number of episodes to process in each batch (to avoid OOM)
        num_workers: Number of parallel workers for processing
    """
    dataset_file = f"data/h5_data/{task_name}.h5"
    
    print(f"Processing {load_num} episodes for {agent_num} agents with batch_size={batch_size} and {num_workers} workers")
    
    if num_workers > 1:
        # Parallel processing mode
        print("Using parallel processing mode")
        
        # Prepare arguments for all episodes
        episode_args = [(i, dataset_file, task_name, agent_num) for i in range(load_num)]
        
        # Process in batches to avoid OOM
        for batch_start in range(0, load_num, batch_size):
            batch_end = min(batch_start + batch_size, load_num)
            batch_args = episode_args[batch_start:batch_end]
            
            print(f"\nProcessing batch {batch_start//batch_size + 1}/{(load_num + batch_size - 1)//batch_size}")
            print(f"Episodes {batch_start} to {batch_end-1}")
            
            # Use multiprocessing pool for parallel processing
            with mp.Pool(processes=min(num_workers, len(batch_args))) as pool:
                results = list(tqdm(
                    pool.imap(process_episode, batch_args),
                    total=len(batch_args),
                    desc=f"Batch {batch_start//batch_size + 1}"
                ))
            
            # Force garbage collection after each batch
            gc.collect()
            print(f"Completed episodes {batch_start} to {batch_end-1}")
    else:
        # Sequential processing mode with batch loading
        print("Using sequential processing mode with batch loading")
        dataset = ManiSkillTrajectoryDataset(
            dataset_file=dataset_file, 
            load_count=load_num,
            batch_size=batch_size  # Enable on-demand loading
        )
        print("--Successfully initialized dataset--")
        
        for i in tqdm(range(load_num), desc="Processing episodes"):
        res = dataset.__getitem__(i)
            
        for agent_id in range(agent_num + 1):
            base_dir = f"data/pkl_data/{task_name}" + "_Agent" + str(agent_id)
            head_camera_name = "head_camera_agent" + str(agent_id)
            wrist_camera_name = "wrist_camera_agent" + str(agent_id)
            if agent_id == agent_num:
                base_dir = f"data/pkl_data/{task_name}" + "_global"
                head_camera_name = "head_camera_global"
                wrist_camera_name = None  # Global doesn't have wrist camera
                
            # for every episode, make a dir to save the episode data
            episode_dir = f"{base_dir}/episode{i}"
            os.makedirs(episode_dir, exist_ok=True)
                
            # Get action length - handle both dict and array structures
            if isinstance(res["action"], dict):
                action_len = len(res["action"]["panda-0"])
            else:
                action_len = len(res["action"])
            
                if head_camera_name not in res["obs"]["sensor_data"]:
                    continue
            
            if (action_len != len(res["obs"]["sensor_data"][head_camera_name]["rgb"])):
                print("action length not equal to obs length")
                print("action length", action_len)
                print("obs length", len(res["obs"]["sensor_data"][head_camera_name]["rgb"]))
            min_len = min(action_len, len(res["obs"]["sensor_data"][head_camera_name]["rgb"]))
                
            for j in range(min_len):
                obs_dict = {}
                # Head camera (side view, fixed position)
                obs_dict["head_camera"] = {}
                obs_dict["head_camera"]["rgb"] = res["obs"]["sensor_data"][head_camera_name]["rgb"][j]
                obs_dict["head_camera"]["intrinsic_cv"] = res["obs"]["sensor_param"][head_camera_name]["intrinsic_cv"][j]
                obs_dict["head_camera"]["extrinsic_cv"] = res["obs"]["sensor_param"][head_camera_name]["extrinsic_cv"][j]
                obs_dict["head_camera"]["cam2world_gl"] = res["obs"]["sensor_param"][head_camera_name]["cam2world_gl"][j]
                
                # Wrist camera (mounted on robot end-effector) - only for agents, not global
                if wrist_camera_name is not None and wrist_camera_name in res["obs"]["sensor_data"]:
                    obs_dict["wrist_camera"] = {}
                    obs_dict["wrist_camera"]["rgb"] = res["obs"]["sensor_data"][wrist_camera_name]["rgb"][j]
                    obs_dict["wrist_camera"]["intrinsic_cv"] = res["obs"]["sensor_param"][wrist_camera_name]["intrinsic_cv"][j]
                    obs_dict["wrist_camera"]["extrinsic_cv"] = res["obs"]["sensor_param"][wrist_camera_name]["extrinsic_cv"][j]
                    obs_dict["wrist_camera"]["cam2world_gl"] = res["obs"]["sensor_param"][wrist_camera_name]["cam2world_gl"][j]
                
                if agent_id == agent_num:
                    step_data = dict(
                        pointcloud=None,
                        joint_action=None,
                        endpose=None,
                        observation=obs_dict,
                    )
                else:
                    # Get action for this agent - handle both dict and array structures
                    if isinstance(res["action"], dict):
                        agent_action = res["action"][f'panda-{agent_id}'][j]
                    else:
                        # For single-agent, use the action directly
                        agent_action = res["action"][j]
                    
                    step_data = dict(
                        pointcloud=None,
                        joint_action=agent_action,
                        endpose=agent_action,
                        observation=obs_dict,
                    )
                with open(f"{episode_dir}/{j}.pkl", "wb") as f:
                    pickle.dump(step_data, f)
            
            # Periodically clean memory
            if (i + 1) % batch_size == 0:
                gc.collect()
    
    print("\nâœ“ All episodes processed successfully!")
    
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--task_name", type=str, required=True, help="Name of the task")
    parser.add_argument("--agent_num", type=int, default=4, help="Number of agents (default: 4)")
    parser.add_argument("--load_num", type=int, required=True, help="Number of trajectories to load")
    parser.add_argument("--batch_size", type=int, default=5, help="Number of episodes to process in each batch (default: 5)")
    parser.add_argument("--num_workers", type=int, default=16, help="Number of parallel workers (default: 16, set to 1 to disable parallelism)")
    args = parser.parse_args()

    # Set multiprocessing start method
    if args.num_workers > 1:
        mp.set_start_method('spawn', force=True)
    
    main(args.load_num, args.task_name, args.agent_num, args.batch_size, args.num_workers)